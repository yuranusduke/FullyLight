% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Model.R
\name{Model}
\alias{Model}
\title{Function to build FullyLight model instance}
\usage{
Model(
  dims,
  input_shape,
  hidden_activation = "relu",
  out_activation = "softmax",
  kernel_initializer = "xavier",
  l1 = 0,
  l2 = 0
)
}
\arguments{
\item{dims}{a vector of numeric numbers. All layers' dims, excluding input layer.}

\item{input_shape}{numeric. Shape of input, should have 784 for MNIST and FashionMNIST.}

\item{hidden_activation}{character string. Hidden layer's activation, default is 'relu', one may also choose 'sigmoid'/'tanh'/'prelu'/'linear'.}

\item{out_activation}{character string. Output activation, default is 'softmax'.}

\item{kernel_initializer}{character string. Default is 'xavier', one can also choose 'random'.}

\item{l1}{numeric. L1 regularization penalty.}

\item{l2}{numeric. L2 regularization penalty.}
}
\value{
A list of instances. \code{model_ins}: model instance and \code{fully_model}: model's definition.
}
\description{
Function will call engine of all inside functions to complete model building using closure,
one may put return into \code{FullyLight::Fit} function.
}
\examples{
dims <- c(20,10,10)
input_shape <- 784
hidden_activation <- 'relu'
kernel_initializer <- 'xavier'
l1 <- 0.01
l2 <- 0.01
models <- Model(dims = dims,
                input_shape = input_shape,
                hidden_activation = hidden_activation,
                out_activation = 'softmax',
                kernel_initializer = kernel_initializer,
                l1 = l1,
                l2 = l2)
}
\author{
Kunhong Yu
}
